Multimodal images are images that are captured with multiple types of sensors. Here each output from each sensor is not fully provided by any of the other sensors. Multimodal image fusion is the process of combining the information from multiple imaging modalities.  

This makes it possible to the exploit the complementary information and relationships between the modalities in tasks down the line. 

In order to fuse the images they need to be aligned, this can be done with joint acquisition (simultaneous collection), manual or automated registration. 

To enable registration there typically needs to be common structures between the modalities that is reflected by the shared or mutual information (**MI**). This is a very difficult task.
[[COMIRs]] reduces this task into a monomodal one that is a simpler task to solve. 

The registration of multimodal images requires that the representations are rotation and translation equivariant, this is in contrast to classification where invariance is required.  




